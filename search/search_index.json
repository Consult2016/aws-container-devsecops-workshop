{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview In this workshop, you will learn how to leverage AWS development tools and open-source projects to integrate automated security testing into a CI/CD pipeline. You will learn about a variety of patterns for integrating security-centric release control into AWS CodePipeline. Additionally, you will learn how to add feedback loops and fix common security vulnerabilities in your container-based applications. Level : Advanced Duration : 2 - 3 hours Prerequisites : AWS Account, Admin IAM User CSF Functions : Prevent, Detect CAF Components : Preventative, Detective AWS Services : Amazon CloudWatch , AWS CodeCommit , AWS CodeBuild , AWS CodePipeline , Amazon ECR , AWS Lambda , and AWS Security Hub Open Source Projects : Hadolint , Trufflehog , and Anchore Scenario Your company has just kicked off a new DevSecOps initiative in an effort to improve the security of critical applications by embedding security in every part of the software development lifecycle. You are part of a DevOps team tasked with integrating security testing into a rudimentary pipeline for building and releasing container images. Your initial tasks include adding Dockerfile linting, secrets scanning, and vulnerability scanning. The decision has been made to evaluate and make use of open source projects with the possibility of moving to a commercial offering based on how well the requirements are met. Architecture For this workshop you will start with a basic CI/CD pipeline that is triggered on Pull Requests and builds and pushes a container image to an Amazon ECR repository. As you work through the tasks in your latest sprint you'll end up with the CI/CD pipeline as shown below. It will include stages within your AWS CodePipeline for linting Dockerfiles, scanning for secrets, and scanning for vulnerabilities including an integration with AWS Security Hub. In addition you will be using a combination of Amazon CloudWatch Event Rules and AWS Lambda Functions to create feedback loops for each stage of security testing. This will allow your developers to quickly fix and iterate on their code which will lead to faster and more secure deliveries. Presentation deck Workshop Presentation Deck Region Please use the us-east-2 (Ohio) region for this workshop. This workshop is broken up into five modules. Please click the bottom right button to proceed to the environment setup.","title":"Overview"},{"location":"#overview","text":"In this workshop, you will learn how to leverage AWS development tools and open-source projects to integrate automated security testing into a CI/CD pipeline. You will learn about a variety of patterns for integrating security-centric release control into AWS CodePipeline. Additionally, you will learn how to add feedback loops and fix common security vulnerabilities in your container-based applications. Level : Advanced Duration : 2 - 3 hours Prerequisites : AWS Account, Admin IAM User CSF Functions : Prevent, Detect CAF Components : Preventative, Detective AWS Services : Amazon CloudWatch , AWS CodeCommit , AWS CodeBuild , AWS CodePipeline , Amazon ECR , AWS Lambda , and AWS Security Hub Open Source Projects : Hadolint , Trufflehog , and Anchore","title":"Overview"},{"location":"#scenario","text":"Your company has just kicked off a new DevSecOps initiative in an effort to improve the security of critical applications by embedding security in every part of the software development lifecycle. You are part of a DevOps team tasked with integrating security testing into a rudimentary pipeline for building and releasing container images. Your initial tasks include adding Dockerfile linting, secrets scanning, and vulnerability scanning. The decision has been made to evaluate and make use of open source projects with the possibility of moving to a commercial offering based on how well the requirements are met.","title":"Scenario"},{"location":"#architecture","text":"For this workshop you will start with a basic CI/CD pipeline that is triggered on Pull Requests and builds and pushes a container image to an Amazon ECR repository. As you work through the tasks in your latest sprint you'll end up with the CI/CD pipeline as shown below. It will include stages within your AWS CodePipeline for linting Dockerfiles, scanning for secrets, and scanning for vulnerabilities including an integration with AWS Security Hub. In addition you will be using a combination of Amazon CloudWatch Event Rules and AWS Lambda Functions to create feedback loops for each stage of security testing. This will allow your developers to quickly fix and iterate on their code which will lead to faster and more secure deliveries.","title":"Architecture"},{"location":"#presentation-deck","text":"Workshop Presentation Deck","title":"Presentation deck"},{"location":"#region","text":"Please use the us-east-2 (Ohio) region for this workshop. This workshop is broken up into five modules. Please click the bottom right button to proceed to the environment setup.","title":"Region"},{"location":"00-env-setup/","text":"Module 0 Environment Setup Time : 15 minutes In the first module you will be configuring the initial pipeline and setting up the Anchore service which you will be integrating into the pipeline later on in this workshop. This module requires you to run two different AWS CloudFormation templates, which will automate the creation of the pipeline and Anchore service. You will then walk through each stage and manually configure the security testing. Deploy the Anchore service The first CloudFormation you run will create the Anchore vulnerability scanning service. Before you deploy the CloudFormation template feel free to view it here . Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. On the Specify Details click Next . Once you have entered your parameters click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and CAPABILITY_AUTO_EXPAND and click Create . What is CAPABILITY_AUTO_EXPAND? Some templates contain macros. Macros perform custom processing on templates; this can include simple actions like find-and-replace operations, all the way to extensive transformations of entire templates. Because of this, users typically create a change set from the processed template, so that they can review the changes resulting from the macros before actually creating the stack. If your stack template contains one or more macros, and you choose to create a stack directly from the processed template, without first reviewing the resulting changes in a change set, you must acknowledge this capability. This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status. Deploy your pipeline The second CloudFormation you run will create the initial pipeline. Before you deploy the CloudFormation template feel free to view it here . Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. On the Specify Details section enter the necessary parameters as shown below. Parameter Value Stack name container-devsecops-wksp Fail When Select a threshold Once you have entered your parameters click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status. Browse to your Cloud9 IDE You will be doing the majority of the workshop using the AWS Command Line Interface (CLI) within AWS Cloud9 , a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. Open the AWS Cloud9 console (us-east-2) Click Open IDE in the container-devsecops-wksp-ide environment. This will take you to your IDE in a new tab. Always keep this tab open Setup your git credentials and clone the repo that contains all the configurations for your pipeline: git config --global credential.helper !aws codecommit credential-helper $@ git config --global credential.UseHttpPath true git clone https://git-codecommit.us-east-2.amazonaws.com/v1/repos/container-devsecops-wksp-config What is aws codecommit credential-helper? The credential-helper utility is not designed to be called directly from the AWS CLI. Instead it is intended to be used as a parameter with the git config command to set up your local computer. It enables Git to use HTTPS and a cryptographically signed version of your IAM user credentials or Amazon EC2 instance role whenever Git needs to authenticate with AWS to interact with CodeCommit repositories. Enable AWS Security Hub You will be using AWS Security Hub to manage your container image vulnerabilities. Enable Security Hub aws securityhub enable-security-hub You can browse to AWS CodePipeline to view your current pipeline. All the stages are there but they have not been properly configured. After you have successfully setup your environment, you can proceed to the next module.","title":"Module 0: Environment Setup"},{"location":"00-env-setup/#module-0-environment-setup","text":"Time : 15 minutes In the first module you will be configuring the initial pipeline and setting up the Anchore service which you will be integrating into the pipeline later on in this workshop. This module requires you to run two different AWS CloudFormation templates, which will automate the creation of the pipeline and Anchore service. You will then walk through each stage and manually configure the security testing.","title":"Module 0 Environment Setup"},{"location":"00-env-setup/#deploy-the-anchore-service","text":"The first CloudFormation you run will create the Anchore vulnerability scanning service. Before you deploy the CloudFormation template feel free to view it here . Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. On the Specify Details click Next . Once you have entered your parameters click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and CAPABILITY_AUTO_EXPAND and click Create . What is CAPABILITY_AUTO_EXPAND? Some templates contain macros. Macros perform custom processing on templates; this can include simple actions like find-and-replace operations, all the way to extensive transformations of entire templates. Because of this, users typically create a change set from the processed template, so that they can review the changes resulting from the macros before actually creating the stack. If your stack template contains one or more macros, and you choose to create a stack directly from the processed template, without first reviewing the resulting changes in a change set, you must acknowledge this capability. This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status.","title":"Deploy the Anchore service"},{"location":"00-env-setup/#deploy-your-pipeline","text":"The second CloudFormation you run will create the initial pipeline. Before you deploy the CloudFormation template feel free to view it here . Region Deploy US East 2 (Ohio) Click the Deploy to AWS button above. This will automatically take you to the console to run the template. On the Specify Details section enter the necessary parameters as shown below. Parameter Value Stack name container-devsecops-wksp Fail When Select a threshold Once you have entered your parameters click Next , then Next again (leave everything on this page at the default). Finally, acknowledge that the template will create IAM roles and click Create . This will bring you back to the CloudFormation console. You can refresh the page to see the stack starting to create. Before moving on, make sure the stack is in a CREATE_COMPLETE status.","title":"Deploy your pipeline"},{"location":"00-env-setup/#browse-to-your-cloud9-ide","text":"You will be doing the majority of the workshop using the AWS Command Line Interface (CLI) within AWS Cloud9 , a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. Open the AWS Cloud9 console (us-east-2) Click Open IDE in the container-devsecops-wksp-ide environment. This will take you to your IDE in a new tab. Always keep this tab open Setup your git credentials and clone the repo that contains all the configurations for your pipeline: git config --global credential.helper !aws codecommit credential-helper $@ git config --global credential.UseHttpPath true git clone https://git-codecommit.us-east-2.amazonaws.com/v1/repos/container-devsecops-wksp-config What is aws codecommit credential-helper? The credential-helper utility is not designed to be called directly from the AWS CLI. Instead it is intended to be used as a parameter with the git config command to set up your local computer. It enables Git to use HTTPS and a cryptographically signed version of your IAM user credentials or Amazon EC2 instance role whenever Git needs to authenticate with AWS to interact with CodeCommit repositories.","title":"Browse to your Cloud9 IDE"},{"location":"00-env-setup/#enable-aws-security-hub","text":"You will be using AWS Security Hub to manage your container image vulnerabilities. Enable Security Hub aws securityhub enable-security-hub You can browse to AWS CodePipeline to view your current pipeline. All the stages are there but they have not been properly configured. After you have successfully setup your environment, you can proceed to the next module.","title":"Enable AWS Security Hub"},{"location":"01-linting/","text":"Module 1 Add a Dockerfile linting stage Time : 15 minutes Now that you have your initial pipeline setup, it is time to start integrating security testing. The first stage you'll add is for doing linting of Dockerfiles to help you build best practice Docker images. For linting you'll be leveraging Hadolint , which is a popular open source project for linting Dockerfiles and validating inline bash. The linter parses the Dockerfile into an AST and performs rules on top of the AST. The rules aren't all security specific but they have good coverage across best practices. View your CodeBuild Project For each AWS CodePipeline stage you'll be using AWS CodeBuild , which is a continuous integration service that compiles source code, runs tests, and produces software packages that are ready to deploy. The CodeBuild project for Dockerfile linting has already been created but hasn't been properly configured. Click here to view your CodeBuild project Create the Build Spec file Each CodeBuild project contains a build specification (build spec) file, which is a collection of build commands and related settings, in YAML format, that CodeBuild uses to run a build. This is the file where you define the commands for doing Dockerfile linting using Hadolint. Click on your Cloud9 IDE tab. In the left file tree, expand the container-devsecops-wksp-config folder and open buildspec_dockerfile.yml . Review the YAML code below, paste it in the file, and save it. version : 0.2 phases : pre_build : commands : - echo Copying hadolint.yml to the application directory - cp hadolint.yml $CODEBUILD_SRC_DIR_AppSource/hadolint.yml - echo Switching to the application directory - cd $CODEBUILD_SRC_DIR_AppSource - echo Pulling the hadolint docker image - docker pull hadolint/hadolint:v1.16.2 build : commands : - echo Build started on `date` - echo Scanning with Hadolint... - result=`docker run --rm -i -v ${PWD}/hadolint.yml:/.hadolint.yaml hadolint/hadolint:v1.16.2 hadolint -f json - Dockerfile` post_build : commands : - echo $result - aws ssm put-parameter --name codebuild-dockerfile-results --type String --value $result --overwrite - echo Build completed on `date` Add the Hadolint configuration When using Hadolint you can optionally specify a configuration file to ignore certain rules you might not necessary care about as well as specify trusted registries. You can view all the current rules by scrolling down on the Hadolint github project In the left file tree, expand the container-devsecops-wksp-config folder and open hadolint.yml . Paste the YAML below and save the file. ignored : - DL3000 - DL3025 trustedRegistries : - examplecorp.com After you have successfully configured the Dockerfile linting stage, you can proceed to the next module.","title":"Module 1: Dockerfile Linting"},{"location":"01-linting/#module-1-add-a-dockerfile-linting-stage","text":"Time : 15 minutes Now that you have your initial pipeline setup, it is time to start integrating security testing. The first stage you'll add is for doing linting of Dockerfiles to help you build best practice Docker images. For linting you'll be leveraging Hadolint , which is a popular open source project for linting Dockerfiles and validating inline bash. The linter parses the Dockerfile into an AST and performs rules on top of the AST. The rules aren't all security specific but they have good coverage across best practices.","title":"Module 1 Add a Dockerfile linting stage"},{"location":"01-linting/#view-your-codebuild-project","text":"For each AWS CodePipeline stage you'll be using AWS CodeBuild , which is a continuous integration service that compiles source code, runs tests, and produces software packages that are ready to deploy. The CodeBuild project for Dockerfile linting has already been created but hasn't been properly configured. Click here to view your CodeBuild project","title":"View your CodeBuild Project"},{"location":"01-linting/#create-the-build-spec-file","text":"Each CodeBuild project contains a build specification (build spec) file, which is a collection of build commands and related settings, in YAML format, that CodeBuild uses to run a build. This is the file where you define the commands for doing Dockerfile linting using Hadolint. Click on your Cloud9 IDE tab. In the left file tree, expand the container-devsecops-wksp-config folder and open buildspec_dockerfile.yml . Review the YAML code below, paste it in the file, and save it. version : 0.2 phases : pre_build : commands : - echo Copying hadolint.yml to the application directory - cp hadolint.yml $CODEBUILD_SRC_DIR_AppSource/hadolint.yml - echo Switching to the application directory - cd $CODEBUILD_SRC_DIR_AppSource - echo Pulling the hadolint docker image - docker pull hadolint/hadolint:v1.16.2 build : commands : - echo Build started on `date` - echo Scanning with Hadolint... - result=`docker run --rm -i -v ${PWD}/hadolint.yml:/.hadolint.yaml hadolint/hadolint:v1.16.2 hadolint -f json - Dockerfile` post_build : commands : - echo $result - aws ssm put-parameter --name codebuild-dockerfile-results --type String --value $result --overwrite - echo Build completed on `date`","title":"Create the Build Spec file"},{"location":"01-linting/#add-the-hadolint-configuration","text":"When using Hadolint you can optionally specify a configuration file to ignore certain rules you might not necessary care about as well as specify trusted registries. You can view all the current rules by scrolling down on the Hadolint github project In the left file tree, expand the container-devsecops-wksp-config folder and open hadolint.yml . Paste the YAML below and save the file. ignored : - DL3000 - DL3025 trustedRegistries : - examplecorp.com After you have successfully configured the Dockerfile linting stage, you can proceed to the next module.","title":"Add the Hadolint configuration"},{"location":"02-secrets-scanning/","text":"Module 2 Add a secrets scanning stage Time : 15 minutes Next, you need to setup a stage for identifying secrets throughout your code. For this stage you'll be leveraging trufflehog , a popular open source project for finding secrets accidentally committed in repositories. It essentially searches through git repositories for secrets, digging deep into commit history and branches. It identifies secrets by running entropy checks as well as high signal regex checks. Create the Build Spec file Click on your Cloud9 IDE tab. In the left file tree, expand the container-devsecops-wksp-config folder and open buildspec_secrets.yml . Review the YAML code below, paste it in the file, and save. version : 0.2 phases : pre_build : commands : - echo Setting CodeCommit Credentials - git config --global credential.helper !aws codecommit credential-helper $@ - git config --global credential.UseHttpPath true - echo Copying secrets_config.json to the application directory - cp secrets_config.json $CODEBUILD_SRC_DIR_AppSource/secrets_config.json - echo Switching to the application directory - echo Installing pip and truffleHog - curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py - python get-pip.py - pip install truffleHog build : commands : - echo Build started on `date` - echo Scanning with truffleHog... - trufflehog --regex --rules secrets_config.json --entropy=False $APP_REPO_URL post_build : commands : - echo Build completed on `date` Add the trufflehog regex configuration When using trufflehog you can optionally specify a configuration file that contains custom regex checks. In the left file tree, expand the container-devsecops-wksp-config folder and open secrets_config.json . Paste the YAML below and save the file. { Slack Token : (xox[p|b|o|a]-[0-9]{12}-[0-9]{12}-[0-9]{12}-[a-z0-9]{32}) , RSA private key : -----BEGIN RSA PRIVATE KEY----- , SSH (OPENSSH) private key : -----BEGIN OPENSSH PRIVATE KEY----- , SSH (DSA) private key : -----BEGIN DSA PRIVATE KEY----- , SSH (EC) private key : -----BEGIN EC PRIVATE KEY----- , PGP private key block : -----BEGIN PGP PRIVATE KEY BLOCK----- , Facebook Oauth : [f|F][a|A][c|C][e|E][b|B][o|O][o|O][k|K].*[ |\\ ][0-9a-f]{32}[ |\\ ] , Twitter Oauth : [t|T][w|W][i|I][t|T][t|T][e|E][r|R].*[ |\\ ][0-9a-zA-Z]{35,44}[ |\\ ] , GitHub : [g|G][i|I][t|T][h|H][u|U][b|B].*[ |\\ ][0-9a-zA-Z]{35,40}[ |\\ ] , Google Oauth : (\\ client_secret\\ :\\ [a-zA-Z0-9-_]{24}\\ ) , AWS API Key : AKIA[0-9A-Z]{16} , Heroku API Key : [h|H][e|E][r|R][o|O][k|K][u|U].*[0-9A-F]{8}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{12} , Generic Secret : [s|S][e|E][c|C][r|R][e|E][t|T].*[ |\\ ][0-9a-zA-Z]{32,45}[ |\\ ] , Generic API Key : [a|A][p|P][i|I][_]?[k|K][e|E][y|Y].*[ |\\ ][0-9a-zA-Z]{32,45}[ |\\ ] , Slack Webhook : https://hooks.slack.com/services/T[a-zA-Z0-9_]{8}/B[a-zA-Z0-9_]{8}/[a-zA-Z0-9_]{24} , Google (GCP) Service-account : \\ type\\ : \\ service_account\\ , Twilio API Key : SK[a-z0-9]{32} , Password in URL : [a-zA-Z]{3,10}://[^/\\\\s:@]{3,20}:[^/\\\\s:@]{3,20}@.{1,100}[\\ \\\\s] } After you have successfully configured the secrets scanning stage, you can proceed to the next module.","title":"Module 2: Secrets Scanning"},{"location":"02-secrets-scanning/#module-2-add-a-secrets-scanning-stage","text":"Time : 15 minutes Next, you need to setup a stage for identifying secrets throughout your code. For this stage you'll be leveraging trufflehog , a popular open source project for finding secrets accidentally committed in repositories. It essentially searches through git repositories for secrets, digging deep into commit history and branches. It identifies secrets by running entropy checks as well as high signal regex checks.","title":"Module 2 Add a secrets scanning stage"},{"location":"02-secrets-scanning/#create-the-build-spec-file","text":"Click on your Cloud9 IDE tab. In the left file tree, expand the container-devsecops-wksp-config folder and open buildspec_secrets.yml . Review the YAML code below, paste it in the file, and save. version : 0.2 phases : pre_build : commands : - echo Setting CodeCommit Credentials - git config --global credential.helper !aws codecommit credential-helper $@ - git config --global credential.UseHttpPath true - echo Copying secrets_config.json to the application directory - cp secrets_config.json $CODEBUILD_SRC_DIR_AppSource/secrets_config.json - echo Switching to the application directory - echo Installing pip and truffleHog - curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py - python get-pip.py - pip install truffleHog build : commands : - echo Build started on `date` - echo Scanning with truffleHog... - trufflehog --regex --rules secrets_config.json --entropy=False $APP_REPO_URL post_build : commands : - echo Build completed on `date`","title":"Create the Build Spec file"},{"location":"02-secrets-scanning/#add-the-trufflehog-regex-configuration","text":"When using trufflehog you can optionally specify a configuration file that contains custom regex checks. In the left file tree, expand the container-devsecops-wksp-config folder and open secrets_config.json . Paste the YAML below and save the file. { Slack Token : (xox[p|b|o|a]-[0-9]{12}-[0-9]{12}-[0-9]{12}-[a-z0-9]{32}) , RSA private key : -----BEGIN RSA PRIVATE KEY----- , SSH (OPENSSH) private key : -----BEGIN OPENSSH PRIVATE KEY----- , SSH (DSA) private key : -----BEGIN DSA PRIVATE KEY----- , SSH (EC) private key : -----BEGIN EC PRIVATE KEY----- , PGP private key block : -----BEGIN PGP PRIVATE KEY BLOCK----- , Facebook Oauth : [f|F][a|A][c|C][e|E][b|B][o|O][o|O][k|K].*[ |\\ ][0-9a-f]{32}[ |\\ ] , Twitter Oauth : [t|T][w|W][i|I][t|T][t|T][e|E][r|R].*[ |\\ ][0-9a-zA-Z]{35,44}[ |\\ ] , GitHub : [g|G][i|I][t|T][h|H][u|U][b|B].*[ |\\ ][0-9a-zA-Z]{35,40}[ |\\ ] , Google Oauth : (\\ client_secret\\ :\\ [a-zA-Z0-9-_]{24}\\ ) , AWS API Key : AKIA[0-9A-Z]{16} , Heroku API Key : [h|H][e|E][r|R][o|O][k|K][u|U].*[0-9A-F]{8}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{12} , Generic Secret : [s|S][e|E][c|C][r|R][e|E][t|T].*[ |\\ ][0-9a-zA-Z]{32,45}[ |\\ ] , Generic API Key : [a|A][p|P][i|I][_]?[k|K][e|E][y|Y].*[ |\\ ][0-9a-zA-Z]{32,45}[ |\\ ] , Slack Webhook : https://hooks.slack.com/services/T[a-zA-Z0-9_]{8}/B[a-zA-Z0-9_]{8}/[a-zA-Z0-9_]{24} , Google (GCP) Service-account : \\ type\\ : \\ service_account\\ , Twilio API Key : SK[a-z0-9]{32} , Password in URL : [a-zA-Z]{3,10}://[^/\\\\s:@]{3,20}:[^/\\\\s:@]{3,20}@.{1,100}[\\ \\\\s] } After you have successfully configured the secrets scanning stage, you can proceed to the next module.","title":"Add the trufflehog regex configuration"},{"location":"03-vuln-scanning/","text":"Module 4 Add a vulnerability scanning stage Time : 15 minutes The last stage you will add will be for identifying vulnerabilities in your contaiiner image. For this stage you'll be using Anchore , a popular open source container compliance platform. This service can do a number of different validations but you will be primarily using it for checking your image for any Common Vulnerabilities and Exposures (CVE). Create the Build Spec file Click on your Cloud9 IDE tab. In the left file tree, expand the container-devsecops-wksp-config folder and open buildspec_vuln.yml . Review the YAML code below, paste it in the file, and save. version : 0.2 phases : pre_build : commands : - apt-get update apt-get install -y python-dev jq - docker pull anchore/engine-cli:v0.3.4 - curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py - python get-pip.py - pip install awscli - $(aws ecr get-login --no-include-email) - ANCHORE_CMD= docker run -e ANCHORE_CLI_URL=$ANCHORE_CLI_URL -e ANCHORE_CLI_USER=$ANCHORE_CLI_USER -e ANCHORE_CLI_PASS=$ANCHORE_CLI_PASS anchore/engine-cli:v0.3.4 anchore-cli - $ANCHORE_CMD registry add $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com awsauto awsauto --registry-type=awsecr || return 0 build : commands : - IMAGE=$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME - docker build $CODEBUILD_SRC_DIR_AppSource -t $IMAGE - docker push $IMAGE post_build : commands : - $ANCHORE_CMD image add $IMAGE - while [ $($ANCHORE_CMD --json image get $IMAGE | jq -r .[0].analysis_status ) != analyzed ]; do sleep 1; done - $ANCHORE_CMD --json image vuln $IMAGE os scan_results.json - jq -c --arg image $IMAGE --arg arn $IMAGE_ARN . + {image_id:$image, image_arn:$arn} scan_results.json tmp.json - mv tmp.json scan_results.json - aws lambda invoke --function-name $FUNCTION_ARN --invocation-type RequestResponse --payload file://scan_results.json outfile - if cat scan_results.json | jq -r --arg threshold $FAIL_WHEN .vulnerabilities[] | (.severity==$threshold) | grep -q true; then echo Vulnerabilties Found exit 1; fi Commit all configuration changes Since you've made changes to a number of files in the configuration repo, you need to commit those changes to ensure your pipeline is pulling in the right files. cd /home/ec2-user/environment/container-devsecops-wksp-config git add . git commit -m Updated Build Spec files and configurations. git push -u origin master After you have successfully configured the secrets scanning stage, you can proceed to the next module.","title":"Module 3: Vulnerability Scanning"},{"location":"03-vuln-scanning/#module-4-add-a-vulnerability-scanning-stage","text":"Time : 15 minutes The last stage you will add will be for identifying vulnerabilities in your contaiiner image. For this stage you'll be using Anchore , a popular open source container compliance platform. This service can do a number of different validations but you will be primarily using it for checking your image for any Common Vulnerabilities and Exposures (CVE).","title":"Module 4 Add a vulnerability scanning stage"},{"location":"03-vuln-scanning/#create-the-build-spec-file","text":"Click on your Cloud9 IDE tab. In the left file tree, expand the container-devsecops-wksp-config folder and open buildspec_vuln.yml . Review the YAML code below, paste it in the file, and save. version : 0.2 phases : pre_build : commands : - apt-get update apt-get install -y python-dev jq - docker pull anchore/engine-cli:v0.3.4 - curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py - python get-pip.py - pip install awscli - $(aws ecr get-login --no-include-email) - ANCHORE_CMD= docker run -e ANCHORE_CLI_URL=$ANCHORE_CLI_URL -e ANCHORE_CLI_USER=$ANCHORE_CLI_USER -e ANCHORE_CLI_PASS=$ANCHORE_CLI_PASS anchore/engine-cli:v0.3.4 anchore-cli - $ANCHORE_CMD registry add $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com awsauto awsauto --registry-type=awsecr || return 0 build : commands : - IMAGE=$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME - docker build $CODEBUILD_SRC_DIR_AppSource -t $IMAGE - docker push $IMAGE post_build : commands : - $ANCHORE_CMD image add $IMAGE - while [ $($ANCHORE_CMD --json image get $IMAGE | jq -r .[0].analysis_status ) != analyzed ]; do sleep 1; done - $ANCHORE_CMD --json image vuln $IMAGE os scan_results.json - jq -c --arg image $IMAGE --arg arn $IMAGE_ARN . + {image_id:$image, image_arn:$arn} scan_results.json tmp.json - mv tmp.json scan_results.json - aws lambda invoke --function-name $FUNCTION_ARN --invocation-type RequestResponse --payload file://scan_results.json outfile - if cat scan_results.json | jq -r --arg threshold $FAIL_WHEN .vulnerabilities[] | (.severity==$threshold) | grep -q true; then echo Vulnerabilties Found exit 1; fi","title":"Create the Build Spec file"},{"location":"03-vuln-scanning/#commit-all-configuration-changes","text":"Since you've made changes to a number of files in the configuration repo, you need to commit those changes to ensure your pipeline is pulling in the right files. cd /home/ec2-user/environment/container-devsecops-wksp-config git add . git commit -m Updated Build Spec files and configurations. git push -u origin master After you have successfully configured the secrets scanning stage, you can proceed to the next module.","title":"Commit all configuration changes"},{"location":"04-testing/","text":"Module 4 Pipeline Testing Time : 30 minutes Now that you have integrated multiple types of security testing into your pipeline you can test it to ensure your stages are effective in properly evaluating the security of your container-based applications. While going through each stage you will fix any misconfiguration or vulnerability so that your sample application is able to successfully passes through each stage and is pushed to AWS ECR. Pipeline Architecture Commit : Developer makes a commit to the Development branch. Pull Request : Developer makes a Pull Request Source Branch: Developement Destination Branch: Master Triggers Rule : A CloudWatch Event Rule is triggered based on the following events: pullRequestSourceBranchUpdated pullRequestCreated Starts CodePipeline : The AWS CodePipeline is setup as a target for the CloudWatch Event Rule and it is started after the CloudWatch Event Rule is triggered Pull Request Stage : The stage pulls in these sources and stores them as artifacts in S3; CodeCommit repository: container-devsecops-wksp-app (development branch) CodeCommit repository: container-devsecops-wksp-config (master branch) Dockerfile Linting Stage : The stage pulls in the artifacts from S3 and uses Hadolint (build spec file and configuration file pulled in from S3) to lint the Dockerfile to ensure it adheres to best practices. Secrets Scanning Stage : The stage runs high signal regex checks directly against the CodeCommit Repository ( container-devsecops-wksp-app - development branch ) Vulnerability Scanning Stage : The stage builds the container image, pushes it to ECR, and triggers an Anchore vulnerability assessment against the image. If the scan results include any vulnerabilites that meet or exceed the threshold the build fails. If the vulnerabilites are lower than the threshold the CodeBuild project will invoke a Lambda function with the scan results as the payload and the Lambda function will push the vulnerabilites into AWS Security Hub for future triaging since the risk for those have been accepted. Image Push : The last stage builds the image using the destination commit hash as the tag and pushes it to AWS ECR. CodeBuild Triggers : If any CodeBuild Project fails a CloudWatch Event Rule is triggered. Triggers Lambda Function : The Lambda Function is setup as a target for the CloudWatch Event Rule and is invoked after the CloudWatch Event Rule is triggered. Adds Feedback to Pull Request : The Lambda Function takes the results from each stage and CodeBuild project and posts a comment back to the Pull Requst. This gives the developers fast feedback so they're able to fix any issues that are identified through the pipeline. Make a commit Now you can test your pipeline to see how your Pull Requests result with an image being built and pushed to AWS ECR. First, make a commit to the development branch of your sample application Within your Cloud9 IDE expand your sample application on the left side. Open the Dockerfile . Add a name to the Label line. Push your commit. cd /home/ec2-user/environment/sample-application git add Dockerfile git commit -m Modified Maintainer in Dockerfile git push -u origin development Create a Pull Request aws codecommit create-pull-request \\ --title Updated Maintainer \\ --description Please review these changes. \\ --targets repositoryName=container-devsecops-wksp-app,sourceReference=development,destinationReference=master Go to your AWS CodePipeline to view the progress and result. View the feedback loop Each time a stage is run the results of the CodeBuild Project are posted back to the Pull Request to act as a feedback loop for developers. Go to the CodeCommit console Click on the latest Pull Request. Click the Activity tab to view the feedback. Stage 1: Fix Dockerfile linting issues In the feedback you should see multiple issues that were identified by the Dockerfile linting stage. The first issue can be fixed by modifying the hadolint configuration. Click on your Cloud9 IDE tab. In the left file tree, expand the container-devsecops-wksp-config folder and open hadolint.yml . DL3026 : Use only an allowed registry in the FROM image Fix : Add - docker.io under trustedRegistries (for testing purposes) Commit your configuration changes: cd /home/ec2-user/environment/container-devsecops-wksp-config git add . git commit -m Added a trusted registry to hadolint configuration. git push -u origin master The next two issues can be fixed by modifying the Dockerfile. In the left file tree, expand the sample-application folder and open Dockerfile . DL3007 : Using latest is prone to errors if the image will ever update. Pin the version explicitly to a release tag Fix : Replace FROM python:latest with FROM python:alpine3.7 DL3002 : Last USER should not be root Fix : Add RUN groupadd -r sasquatch useradd -r -g sasquatch sasquatch Fix : Replace USER root with USER sasquatch Commit your application source code changes: cd /home/ec2-user/environment/sample-application git add Dockerfile git commit -m Fixed Dockerfile linting issues. git push -u origin development View the Pull Request Feedback 1. Go to the CodeCommit console 2. Click on the latest Pull Request. 3. Click the Activity tab to view the feedback. Stage 2: Remove secrets Based on the feedback you received in the Pull request you can see that secrets were identified in your code. Click on Logs in the comment or view the CodeBuild Project history to identify the secret and the file it is located in. How could you improve the feedback loop to remove this step? Remove the secret from the file. Modify build spec to only scan a max depth of 1 commit (Removing secrets from previous commits and revoking any credentials are best practices but are not in scope due to time constraints.) Commit your changes Stage 3: Vulnerability Scanning Stage Congratulations! You've completed the Integrating security into your container pipeline workshop. You can proceed to the next module to clean up the resources in your account.","title":"Module 4: Pipeline Testing"},{"location":"04-testing/#module-4-pipeline-testing","text":"Time : 30 minutes Now that you have integrated multiple types of security testing into your pipeline you can test it to ensure your stages are effective in properly evaluating the security of your container-based applications. While going through each stage you will fix any misconfiguration or vulnerability so that your sample application is able to successfully passes through each stage and is pushed to AWS ECR.","title":"Module 4 Pipeline Testing"},{"location":"04-testing/#pipeline-architecture","text":"Commit : Developer makes a commit to the Development branch. Pull Request : Developer makes a Pull Request Source Branch: Developement Destination Branch: Master Triggers Rule : A CloudWatch Event Rule is triggered based on the following events: pullRequestSourceBranchUpdated pullRequestCreated Starts CodePipeline : The AWS CodePipeline is setup as a target for the CloudWatch Event Rule and it is started after the CloudWatch Event Rule is triggered Pull Request Stage : The stage pulls in these sources and stores them as artifacts in S3; CodeCommit repository: container-devsecops-wksp-app (development branch) CodeCommit repository: container-devsecops-wksp-config (master branch) Dockerfile Linting Stage : The stage pulls in the artifacts from S3 and uses Hadolint (build spec file and configuration file pulled in from S3) to lint the Dockerfile to ensure it adheres to best practices. Secrets Scanning Stage : The stage runs high signal regex checks directly against the CodeCommit Repository ( container-devsecops-wksp-app - development branch ) Vulnerability Scanning Stage : The stage builds the container image, pushes it to ECR, and triggers an Anchore vulnerability assessment against the image. If the scan results include any vulnerabilites that meet or exceed the threshold the build fails. If the vulnerabilites are lower than the threshold the CodeBuild project will invoke a Lambda function with the scan results as the payload and the Lambda function will push the vulnerabilites into AWS Security Hub for future triaging since the risk for those have been accepted. Image Push : The last stage builds the image using the destination commit hash as the tag and pushes it to AWS ECR. CodeBuild Triggers : If any CodeBuild Project fails a CloudWatch Event Rule is triggered. Triggers Lambda Function : The Lambda Function is setup as a target for the CloudWatch Event Rule and is invoked after the CloudWatch Event Rule is triggered. Adds Feedback to Pull Request : The Lambda Function takes the results from each stage and CodeBuild project and posts a comment back to the Pull Requst. This gives the developers fast feedback so they're able to fix any issues that are identified through the pipeline.","title":"Pipeline Architecture"},{"location":"04-testing/#make-a-commit","text":"Now you can test your pipeline to see how your Pull Requests result with an image being built and pushed to AWS ECR. First, make a commit to the development branch of your sample application Within your Cloud9 IDE expand your sample application on the left side. Open the Dockerfile . Add a name to the Label line. Push your commit. cd /home/ec2-user/environment/sample-application git add Dockerfile git commit -m Modified Maintainer in Dockerfile git push -u origin development","title":"Make a commit"},{"location":"04-testing/#create-a-pull-request","text":"aws codecommit create-pull-request \\ --title Updated Maintainer \\ --description Please review these changes. \\ --targets repositoryName=container-devsecops-wksp-app,sourceReference=development,destinationReference=master Go to your AWS CodePipeline to view the progress and result.","title":"Create a Pull Request"},{"location":"04-testing/#view-the-feedback-loop","text":"Each time a stage is run the results of the CodeBuild Project are posted back to the Pull Request to act as a feedback loop for developers. Go to the CodeCommit console Click on the latest Pull Request. Click the Activity tab to view the feedback.","title":"View the feedback loop"},{"location":"04-testing/#stage-1-fix-dockerfile-linting-issues","text":"In the feedback you should see multiple issues that were identified by the Dockerfile linting stage. The first issue can be fixed by modifying the hadolint configuration. Click on your Cloud9 IDE tab. In the left file tree, expand the container-devsecops-wksp-config folder and open hadolint.yml . DL3026 : Use only an allowed registry in the FROM image Fix : Add - docker.io under trustedRegistries (for testing purposes) Commit your configuration changes: cd /home/ec2-user/environment/container-devsecops-wksp-config git add . git commit -m Added a trusted registry to hadolint configuration. git push -u origin master The next two issues can be fixed by modifying the Dockerfile. In the left file tree, expand the sample-application folder and open Dockerfile . DL3007 : Using latest is prone to errors if the image will ever update. Pin the version explicitly to a release tag Fix : Replace FROM python:latest with FROM python:alpine3.7 DL3002 : Last USER should not be root Fix : Add RUN groupadd -r sasquatch useradd -r -g sasquatch sasquatch Fix : Replace USER root with USER sasquatch Commit your application source code changes: cd /home/ec2-user/environment/sample-application git add Dockerfile git commit -m Fixed Dockerfile linting issues. git push -u origin development View the Pull Request Feedback 1. Go to the CodeCommit console 2. Click on the latest Pull Request. 3. Click the Activity tab to view the feedback.","title":"Stage 1: Fix Dockerfile linting issues"},{"location":"04-testing/#stage-2-remove-secrets","text":"Based on the feedback you received in the Pull request you can see that secrets were identified in your code. Click on Logs in the comment or view the CodeBuild Project history to identify the secret and the file it is located in. How could you improve the feedback loop to remove this step? Remove the secret from the file. Modify build spec to only scan a max depth of 1 commit (Removing secrets from previous commits and revoking any credentials are best practices but are not in scope due to time constraints.) Commit your changes","title":"Stage 2: Remove secrets"},{"location":"04-testing/#stage-3-vulnerability-scanning-stage","text":"Congratulations! You've completed the Integrating security into your container pipeline workshop. You can proceed to the next module to clean up the resources in your account.","title":"Stage 3: Vulnerability Scanning Stage"},{"location":"05-cleanup/","text":"Module 5: Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forgot about it, and then accrue charges. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. Retrieve your AWS Account Open your Cloud9 IDE Retrieve and copy your AWS Account # aws sts get-caller-identity Delete the artifact S3 bucket Delete all objects in the bucket (Replace ): aws s3 rm s3://container-devsecops-wksp- ACCOUNT# -us-east-2-artifacts --recursive Delete bucket (Replace ): aws s3api delete-bucket --bucket container-devsecops-wksp- ACCOUNT# -us-east-2-artifacts Delete the AWS CloudWatch Log Groups aws logs delete-log-group --log-group-name /aws/codebuild/container-devsecops-wksp-build-dockerfile aws logs delete-log-group --log-group-name /aws/lambda/container-devsecops-wksp-codebuild-dockerfile aws logs delete-log-group --log-group-name /aws/lambda/container-devsecops-wksp-initial-commit Delete the AWS ECR repositories aws ecr delete-repository --repository-name container-devsecops-wksp-sample aws ecr delete-repository --repository-name container-devsecops-wksp-anchore Delete CloudFormation templates Delete the pipeline stack: aws cloudformation delete-stack --stack-name container-dso-wksp-pipeline-stack Delete the Anchore service: aws cloudformation delete-stack --stack-name container-dso-wksp-pipeline-stack","title":"Module 5: Cleanup"},{"location":"05-cleanup/#module-5-cleanup","text":"In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forgot about it, and then accrue charges. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order.","title":"Module 5: Cleanup"},{"location":"05-cleanup/#retrieve-your-aws-account","text":"Open your Cloud9 IDE Retrieve and copy your AWS Account # aws sts get-caller-identity","title":"Retrieve your AWS Account"},{"location":"05-cleanup/#delete-the-artifact-s3-bucket","text":"Delete all objects in the bucket (Replace ): aws s3 rm s3://container-devsecops-wksp- ACCOUNT# -us-east-2-artifacts --recursive Delete bucket (Replace ): aws s3api delete-bucket --bucket container-devsecops-wksp- ACCOUNT# -us-east-2-artifacts","title":"Delete the artifact S3 bucket"},{"location":"05-cleanup/#delete-the-aws-cloudwatch-log-groups","text":"aws logs delete-log-group --log-group-name /aws/codebuild/container-devsecops-wksp-build-dockerfile aws logs delete-log-group --log-group-name /aws/lambda/container-devsecops-wksp-codebuild-dockerfile aws logs delete-log-group --log-group-name /aws/lambda/container-devsecops-wksp-initial-commit","title":"Delete the AWS CloudWatch Log Groups"},{"location":"05-cleanup/#delete-the-aws-ecr-repositories","text":"aws ecr delete-repository --repository-name container-devsecops-wksp-sample aws ecr delete-repository --repository-name container-devsecops-wksp-anchore","title":"Delete the AWS ECR repositories"},{"location":"05-cleanup/#delete-cloudformation-templates","text":"Delete the pipeline stack: aws cloudformation delete-stack --stack-name container-dso-wksp-pipeline-stack Delete the Anchore service: aws cloudformation delete-stack --stack-name container-dso-wksp-pipeline-stack","title":"Delete CloudFormation templates"},{"location":"contribute/","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Reporting Bugs/Feature Requests We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment Contributing via Pull Requests Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request . Finding contributions to work on Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start. Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments. Security issue notifications If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue. Licensing See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"contribute/#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.","title":"Contributing Guidelines"},{"location":"contribute/#reporting-bugsfeature-requests","text":"We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment","title":"Reporting Bugs/Feature Requests"},{"location":"contribute/#contributing-via-pull-requests","text":"Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: You are working against the latest source on the master branch. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request .","title":"Contributing via Pull Requests"},{"location":"contribute/#finding-contributions-to-work-on","text":"Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.","title":"Finding contributions to work on"},{"location":"contribute/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"contribute/#security-issue-notifications","text":"If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue.","title":"Security issue notifications"},{"location":"contribute/#licensing","text":"See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Licensing"},{"location":"license/","text":"License MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"}]}